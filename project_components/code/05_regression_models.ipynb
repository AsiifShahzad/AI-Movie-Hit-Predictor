{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Regression Models - Movie Revenue Prediction\n",
    "\n",
    "## Overview\n",
    "Compare baseline and advanced regression models for revenue prediction:\n",
    "- Linear Regression, Ridge, Lasso (Baseline)\n",
    "- Random Forest, XGBoost, LightGBM (Advanced)\n",
    "- Hyperparameter optimization with GridSearchCV/RandomizedSearchCV\n",
    "- Evaluation: RMSE, MAE, R², Cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 11506 rows × 106 columns\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "PROJECT_ROOT = Path('/home/asif/AI-Movie-Hit-Predictor')\n",
    "DATA_DIR = PROJECT_ROOT / 'project_components' / 'data'\n",
    "\n",
    "# Load engineered features\n",
    "df = pd.read_csv(DATA_DIR / '04_engineered_features.csv')\n",
    "print(f'Dataset loaded: {df.shape[0]} rows × {df.shape[1]} columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ML libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import ML Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "print('All ML libraries imported successfully!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Baseline Models (Linear Regression, Ridge, Lasso)\n",
    "Compare simple linear models with various regularization approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3842 samples\n",
      "Test set: 961 samples\n",
      "Features: 34\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "df_modeling = df[df['revenue'].notna()].copy()\n",
    "df_modeling['log_revenue'] = np.log1p(df_modeling['revenue'])\n",
    "\n",
    "# Select features - exclude non-numeric and ID columns\n",
    "exclude_cols = ['id', 'title', 'revenue', 'budget', 'release_date', 'genres', 'cast', 'crew',\n",
    "                'original_title', 'genres_list', 'cast_list', 'director_list', 'primary_genre',\n",
    "                'primary_company', 'overview', 'tagline', 'homepage', 'keywords', 'company_list',\n",
    "                'original_language', 'status', 'production_companies']\n",
    "\n",
    "# Get only numeric columns\n",
    "feature_cols = [col for col in df_modeling.select_dtypes(include=[np.number]).columns \n",
    "                if col not in exclude_cols]\n",
    "\n",
    "X = df_modeling[feature_cols].fillna(df_modeling[feature_cols].median(numeric_only=True))\n",
    "y = df_modeling['log_revenue']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Training set: {X_train.shape[0]} samples')\n",
    "print(f'Test set: {X_test.shape[0]} samples')\n",
    "print(f'Features: {X_train.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R²: 1.0000\n",
      "Ridge R²: 1.0000\n",
      "Lasso R²: 0.9992\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'Model': model_name, 'RMSE': rmse, 'MAE': mae, 'R²': r2}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "results.append(evaluate_model(y_test, y_pred_lr, 'Linear Regression'))\n",
    "print(f'Linear Regression R²: {results[-1][\"R²\"]:.4f}')\n",
    "\n",
    "# Ridge\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test_scaled)\n",
    "results.append(evaluate_model(y_test, y_pred_ridge, 'Ridge'))\n",
    "print(f'Ridge R²: {results[-1][\"R²\"]:.4f}')\n",
    "\n",
    "# Lasso\n",
    "lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test_scaled)\n",
    "results.append(evaluate_model(y_test, y_pred_lasso, 'Lasso'))\n",
    "print(f'Lasso R²: {results[-1][\"R²\"]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Advanced Models (Random Forest, XGBoost, LightGBM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest R²: 1.0000\n",
      "XGBoost R²: 0.9996\n",
      "LightGBM R²: 0.9999\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "results.append(evaluate_model(y_test, y_pred_rf, 'Random Forest'))\n",
    "print(f'Random Forest R²: {results[-1][\"R²\"]:.4f}')\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "results.append(evaluate_model(y_test, y_pred_xgb, 'XGBoost'))\n",
    "print(f'XGBoost R²: {results[-1][\"R²\"]:.4f}')\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=100, random_state=42, verbosity=-1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "results.append(evaluate_model(y_test, y_pred_lgb, 'LightGBM'))\n",
    "print(f'LightGBM R²: {results[-1][\"R²\"]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV for XGBoost...\n",
      "Best params: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200}\n",
      "XGBoost Optimized R²: 0.9998\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Hyperparameter Tuning\n",
    "xgb_param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "print('GridSearchCV for XGBoost...')\n",
    "xgb_grid = GridSearchCV(xgb.XGBRegressor(random_state=42), xgb_param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "print(f'Best params: {xgb_grid.best_params_}')\n",
    "\n",
    "xgb_optimized = xgb_grid.best_estimator_\n",
    "y_pred_xgb_opt = xgb_optimized.predict(X_test)\n",
    "results.append(evaluate_model(y_test, y_pred_xgb_opt, 'XGBoost (Optimized)'))\n",
    "print(f'XGBoost Optimized R²: {results[-1][\"R²\"]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Model Results:\n",
      "              Model         RMSE          MAE       R²\n",
      "  Linear Regression 9.828037e-15 7.761626e-15 1.000000\n",
      "              Ridge 1.405730e-02 1.126106e-02 0.999997\n",
      "              Lasso 2.319862e-01 2.092521e-01 0.999213\n",
      "      Random Forest 4.023878e-02 4.532151e-03 0.999976\n",
      "            XGBoost 1.569382e-01 3.434944e-02 0.999640\n",
      "           LightGBM 6.727545e-02 1.809754e-02 0.999934\n",
      "XGBoost (Optimized) 1.303074e-01 2.996609e-02 0.999752\n",
      "\n",
      "✓ Best model saved to: /home/asif/AI-Movie-Hit-Predictor/project_components/data/models/best_regression_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Show all results\n",
    "results_df = pd.DataFrame(results)\n",
    "print('\\nAll Model Results:')\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Create models directory\n",
    "MODEL_DIR = DATA_DIR / 'models'\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Save best model\n",
    "best_model_path = MODEL_DIR / 'best_regression_model.pkl'\n",
    "with open(best_model_path, 'wb') as f:\n",
    "    pickle.dump(xgb_optimized, f)\n",
    "print(f'\\n✓ Best model saved: {best_model_path}')\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = MODEL_DIR / 'regression_scaler.pkl'\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f'✓ Scaler saved: {scaler_path}')\n",
    "\n",
    "# Save feature columns\n",
    "feature_cols_path = MODEL_DIR / 'regression_feature_columns.pkl'\n",
    "with open(feature_cols_path, 'wb') as f:\n",
    "    pickle.dump(feature_cols, f)\n",
    "print(f'✓ Feature columns saved: {feature_cols_path}')\n",
    "\n",
    "# Save model results\n",
    "results_path = DATA_DIR / '05_regression_model_results.csv'\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f'✓ Model results saved: {results_path}')\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred_xgb_opt,\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_xgb_opt)),\n",
    "    'MAE': mean_absolute_error(y_test, y_pred_xgb_opt),\n",
    "    'R2': r2_score(y_test, y_pred_xgb_opt)\n",
    "})\n",
    "predictions_path = DATA_DIR / '05_regression_predictions.csv'\n",
    "predictions_df.to_csv(predictions_path, index=False)\n",
    "print(f'✓ Predictions saved: {predictions_path}')\n",
    "\n",
    "print(f'\\n✓ All regression models, scalers, and results saved successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
