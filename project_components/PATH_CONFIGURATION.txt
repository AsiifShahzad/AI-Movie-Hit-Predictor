# Project Structure & Path Configuration
**Version**: 1.0  
**Last Updated**: January 28, 2026  
**Status**: ✓ VERIFIED & VALIDATED

---

## Directory Structure

```
/home/asif/AI-Movie-Hit-Predictor/
├── project_components/
│   ├── code/                          # All code notebooks here
│   │   ├── data_handeling.ipynb       # Data consolidation pipeline
│   │   └── eda_feature_engineering.ipynb  # EDA & feature engineering
│   │
│   └── data/                          # All data files here
│       ├── 01_raw_tmdb_10000_movies.csv (3.3 MB) ✓ EXISTS
│       ├── 02_raw_tmdb_5000_movies.csv (5.4 MB) ✓ EXISTS
│       ├── 03_consolidated_movies.csv (pending generation)
│       └── 04_engineered_features.csv (pending generation)
│
├── .git/                              # Version control
├── .venv/                             # Virtual environment
└── README.md
```

---

## Path Configuration

### Base Paths
All notebooks should use these base paths:

```python
PROJECT_ROOT = Path("/home/asif/AI-Movie-Hit-Predictor")
DATA_DIR = PROJECT_ROOT / "project_components" / "data"
CODE_DIR = PROJECT_ROOT / "project_components" / "code"
```

### Data File Paths
Use these paths to reference data files:

```python
# Input raw datasets
DATASET_PATH_10K = DATA_DIR / "01_raw_tmdb_10000_movies.csv"
DATASET_PATH_5K = DATA_DIR / "02_raw_tmdb_5000_movies.csv"

# Output consolidated dataset
CONSOLIDATED_DATA = DATA_DIR / "03_consolidated_movies.csv"

# Output engineered features
ENGINEERED_DATA = DATA_DIR / "04_engineered_features.csv"
```

---

## Data Files Status

| File | Size | Status | Purpose |
|------|------|--------|---------|
| 01_raw_tmdb_10000_movies.csv | 3.3 MB | ✓ EXISTS | Raw TMDB 10K dataset (raw input) |
| 02_raw_tmdb_5000_movies.csv | 5.4 MB | ✓ EXISTS | Raw TMDB 5K dataset (raw input) |
| 03_consolidated_movies.csv | TBD | ⏳ PENDING | Generated by data_handeling.ipynb |
| 04_engineered_features.csv | TBD | ⏳ PENDING | Generated by eda_feature_engineering.ipynb |

---

## Notebook Locations & Flow

### Phase 1: Data Consolidation
**File**: `project_components/code/data_handeling.ipynb`

**Purpose**: Merge, deduplicate, and standardize data

**Inputs**:
- `project_components/data/01_raw_tmdb_10000_movies.csv`
- `project_components/data/02_raw_tmdb_5000_movies.csv`

**Outputs**:
- `project_components/data/03_consolidated_movies.csv`

**Path Configuration in Notebook**:
```python
PROJECT_ROOT = Path("/home/asif/AI-Movie-Hit-Predictor")
DATA_DIR = PROJECT_ROOT / "project_components" / "data"
DATASET_PATH_5K = DATA_DIR / "02_raw_tmdb_5000_movies.csv"
DATASET_PATH_10K = DATA_DIR / "01_raw_tmdb_10000_movies.csv"
output_path = DATA_DIR / "03_consolidated_movies.csv"
```

### Phase 2: EDA & Feature Engineering
**File**: `project_components/code/eda_feature_engineering.ipynb`

**Purpose**: Exploratory analysis and create ML-ready features

**Inputs**:
- `project_components/data/03_consolidated_movies.csv`

**Outputs**:
- `project_components/data/04_engineered_features.csv`

**Path Configuration in Notebook**:
```python
PROJECT_ROOT = Path("/home/asif/AI-Movie-Hit-Predictor")
DATA_DIR = PROJECT_ROOT / "project_components" / "data"
CONSOLIDATED_DATA = DATA_DIR / "03_consolidated_movies.csv"
output_path = DATA_DIR / "04_engineered_features.csv"
```

---

## Important Path Notes

### ✓ CORRECT PRACTICES
- All relative paths use `Path` objects from `pathlib`
- All notebooks define `PROJECT_ROOT` and `DATA_DIR` at the top
- Output files saved to `DATA_DIR` with proper naming
- Future data files will automatically go to `data/` folder
- Future code notebooks will go to `code/` folder

### ✗ ISSUES AVOIDED
- ❌ No hardcoded absolute paths in logic
- ❌ No files scattered in root directory
- ❌ No inconsistent naming schemes
- ❌ No mixed code and data storage

---

## File Naming Convention

### Data Files
`[order]_[stage]_[description].csv`

Examples:
- `01_raw_tmdb_10000_movies.csv` → First raw dataset (TMDB 10K)
- `02_raw_tmdb_5000_movies.csv` → Second raw dataset (TMDB 5K)
- `03_consolidated_movies.csv` → After consolidation
- `04_engineered_features.csv` → After feature engineering

### Code Files
`[name].ipynb`

Examples:
- `data_handeling.ipynb` → Data consolidation
- `eda_feature_engineering.ipynb` → EDA & features
- `model_development.ipynb` → Model training (future)
- `model_evaluation.ipynb` → Model evaluation (future)

---

## Verification Checklist

| Item | Status | Notes |
|------|--------|-------|
| Directories created | ✓ | project_components/data and /code exist |
| Raw data files renamed | ✓ | All use proper naming (01_, 02_ prefix) |
| Raw data in data/ folder | ✓ | Both CSV files in correct location |
| Code notebooks in code/ folder | ✓ | Both .ipynb files in correct location |
| Path references updated | ✓ | All notebooks use DATA_DIR variable |
| Output paths configured | ✓ | Notebooks save to data/ folder |
| No .md files in root | ✓ | Documentation structure clean |

---

## Next Steps for Data Generation

### To Generate 03_consolidated_movies.csv:
1. Open `project_components/code/data_handeling.ipynb`
2. Run all cells sequentially
3. File will be automatically saved to `project_components/data/03_consolidated_movies.csv`

### To Generate 04_engineered_features.csv:
1. Ensure `03_consolidated_movies.csv` exists (from previous step)
2. Open `project_components/code/eda_feature_engineering.ipynb`
3. Run all cells sequentially
4. File will be automatically saved to `project_components/data/04_engineered_features.csv`

---

## Troubleshooting Path Issues

### Problem: "FileNotFoundError: No such file or directory"
**Solution**: Check that you're using `DATA_DIR` correctly:
```python
# Correct
path = DATA_DIR / "filename.csv"

# Incorrect (will fail)
path = "project_components/data/filename.csv"
```

### Problem: Files saved to wrong location
**Solution**: Ensure output paths use DATA_DIR:
```python
# Correct
output_path = DATA_DIR / "03_consolidated_movies.csv"
df.to_csv(output_path, index=False)

# Incorrect (saves to relative path)
df.to_csv("consolidated_movies.csv", index=False)
```

### Problem: "Path /home/asif/... doesn't exist"
**Solution**: Verify directories exist:
```python
DATA_DIR.mkdir(parents=True, exist_ok=True)
CODE_DIR.mkdir(parents=True, exist_ok=True)
```

---

## Reference Commands

View all files in project structure:
```bash
find /home/asif/AI-Movie-Hit-Predictor/project_components -type f
```

Check data folder:
```bash
ls -lah /home/asif/AI-Movie-Hit-Predictor/project_components/data/
```

Check code folder:
```bash
ls -lah /home/asif/AI-Movie-Hit-Predictor/project_components/code/
```

---

## Summary

✓ **All paths verified and validated**  
✓ **Folder structure properly organized**  
✓ **Data files correctly named and located**  
✓ **Code notebooks in proper location**  
✓ **Path configuration documented**  

**Ready for notebook execution to generate consolidated and engineered datasets.**
